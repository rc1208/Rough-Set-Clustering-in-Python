{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "_author_ = \"Rahul_Chowdhury\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V0</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   V0  V1  V2  V3  V4\n",
       "0   1  23   3   1  19\n",
       "1   2  15   3   1  17\n",
       "2   1  23   3   2  49\n",
       "3   1   5   2   2  33\n",
       "4   2   7  11   2  55\n",
       "5   2  23   3   1  20\n",
       "6   2   9   5   2  19\n",
       "7   2  10   3   2  27\n",
       "8   1  22   3   1  58\n",
       "9   2  15   3   1  20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_url = (\"https://archive.ics.uci.edu/ml/machine-learning-databases/tae/tae.data\")\n",
    "Data = pd.read_csv(target_url, header=None, prefix = \"V\")\n",
    "k = len(list(Data['V5'].unique())) #counting the number of classes in the last column\n",
    "\n",
    "Data = Data.drop(Data.columns[[5]], axis=1) #removing 1st and last column\n",
    "Data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V3 0.6887417218543046\n",
      "V2 0.75\n",
      "V1 0.75\n",
      "V0 0.8133248790568784\n",
      "V4 0.75\n",
      "V3\n",
      "V3\n",
      "Cluster [0, 1, 5, 8, 9, 18, 23, 33, 39, 40, 44, 48, 57, 62, 72, 78, 79, 82, 85, 86, 87, 101, 102]\n",
      "23\n",
      "Cluster [2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]\n",
      "128\n",
      "Cluster [0, 1, 5, 8, 9, 18, 23, 33, 39, 40, 44, 48, 57, 62, 72, 78, 79, 82, 85, 86, 87, 101, 102]\n",
      "Cluster distance 2.45849802372\n",
      "Cluster [2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]\n",
      "Cluster distance 3.08218503937\n",
      "C length: 2\n",
      "V2 0.6666666666666666\n",
      "V1 0.6666666666666666\n",
      "V0 0.6896186440677966\n",
      "V4 0.6666666666666666\n",
      "V2\n",
      "V2\n",
      "Cluster [11, 30, 32, 50, 69, 71, 99, 109, 116, 119, 125, 128, 137, 149]\n",
      "14\n",
      "Cluster [2, 3, 4, 6, 7, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 73, 74, 75, 76, 77, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150]\n",
      "114\n",
      "Cluster [0, 1, 5, 8, 9, 18, 23, 33, 39, 40, 44, 48, 57, 62, 72, 78, 79, 82, 85, 86, 87, 101, 102]\n",
      "Cluster distance 2.45849802372\n",
      "Cluster [2, 3, 4, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]\n",
      "Cluster distance 3.08218503937\n",
      "Cluster [11, 30, 32, 50, 69, 71, 99, 109, 116, 119, 125, 128, 137, 149]\n",
      "Cluster distance 1.8021978022\n",
      "Cluster [2, 3, 4, 6, 7, 10, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 38, 41, 42, 43, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 73, 74, 75, 76, 77, 80, 81, 83, 84, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 100, 103, 104, 105, 106, 107, 108, 110, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150]\n",
      "Cluster distance 3.08523521192\n",
      "C length: 3\n"
     ]
    }
   ],
   "source": [
    "cluster2_numerical_global = [] #global variable\n",
    "\n",
    "def MMeR(U,k):\n",
    "    C =  {}#the clusters made through MMeR alogrithm\n",
    "    C_distance = {}\n",
    "    Rough_Data = U.copy()\n",
    "    index = 0\n",
    "   \n",
    "    while(3>len(C.keys())):\n",
    "         \n",
    "        split_attr,min_roughness_attr_value = mmer_roughness(Rough_Data)\n",
    "        print(split_attr)\n",
    "        #min_roughness_attr_value = min(roughness_list_dict[split_attr]) #find the min. value of min_roughness_attr for which alpha is minimum\n",
    "        #print(min_roughness_attr_value)\n",
    "        if(split_attr == 'V1'):\n",
    "            cluster1 = cluster1_numerical_global\n",
    "            #print(\"split-cluster1\",cluster1 )\n",
    "            cluster2 = cluster2_numerical_global\n",
    "            #print(\"split-cluster2\",cluster2 )\n",
    "        else:    \n",
    "            cluster1 = Rough_Data[Rough_Data[split_attr] == min_roughness_attr_value].index.tolist()\n",
    "            cluster2 = Rough_Data.loc[Rough_Data[split_attr] != min_roughness_attr_value].index.tolist()\n",
    "            \n",
    "        cluster1_distance = cluster_distance(cluster1, Data) #calculating the cluster distance of cluster1\n",
    "        cluster2_distance = cluster_distance(cluster2, Data) #calculating the cluster distance of cluster2\n",
    "        C[index] = cluster1\n",
    "        C_distance[index] = cluster1_distance\n",
    "        index += 1\n",
    "        C[index] = cluster2\n",
    "        C_distance[index] = cluster2_distance\n",
    "        index += 1\n",
    "        max_index = max(C_distance, key= C_distance.get) #find the index with the max cluster distance\n",
    "        \n",
    "              \n",
    "        Rough_Data = U.ix[C[max_index]]  #send data of cluster with max distance\n",
    "        for key in C:\n",
    "            print(\"Cluster\",C[key])\n",
    "            print(\"Cluster distance\", C_distance[key])\n",
    "      \n",
    "        \n",
    "        if(len(C.keys())!= (k-1)):\n",
    "               \n",
    "            del C[max_index]\n",
    "            del C_distance[max_index]\n",
    "        \n",
    "        print(\"C length:\",len(C.keys()))\n",
    "       \n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "def roughness(col_name1, col_name2, val, Data):\n",
    "     \n",
    "     equiv_class_dict = {} #dictionary storing equiv classes for all attribute\n",
    "     for col in Data:\n",
    "        equiv_class_dict[col] =list(Data.groupby([col]))\n",
    "        \n",
    "     arr = equiv_class_dict[col_name2] #group equiv classes according to column2\n",
    "     target_set = Data[Data[col_name1] == val].index.tolist() #calculating target set for each unique value in column1\n",
    "     lower_approx = []\n",
    "     upper_approx = []\n",
    "     for name,group in arr:\n",
    "       selected_list = list(group.index)\n",
    "       if(set(selected_list).issubset(target_set)): #if a subset, then append to lower_approx\n",
    "            lower_approx.append(selected_list)\n",
    "       if(set(selected_list) & set(target_set)): #if intersection is not null, then append to upper_approx\n",
    "            upper_approx.append(selected_list)\n",
    "     lower_approx_count = sum(map(len, lower_approx)) #count the no. of elements in lower_approx\n",
    "     upper_approx_count = sum(map(len, upper_approx))\n",
    "     if(lower_approx_count == 0):\n",
    "        roughness = 1\n",
    "     else:   \n",
    "         roughness = 1 - (lower_approx_count/upper_approx_count) # return roughness for a(i) = alpha\n",
    "     return roughness\n",
    "\n",
    "def roughness_categorical_to_numerical(neighborhood_class_dict, col_name1, col_name2, val, Data):\n",
    "   \n",
    "    target_set = Data[Data[col_name1] == val].index.tolist() #calculating target set for each unique value in column1\n",
    "    lower_approx1 = []\n",
    "    upper_approx1= []\n",
    "    for k in neighborhood_class_dict:\n",
    "       selected_list = neighborhood_class_dict[k]\n",
    "       if(set(selected_list).issubset(target_set)): #if a subset, then append to lower_approx\n",
    "            lower_approx1.append(k)\n",
    "       if(set(selected_list) & set(target_set)): #if intersection is not null, then append to upper_approx\n",
    "            upper_approx1.append(k)\n",
    "    lower_approx_count = len(lower_approx1) #count the no. of elements in lower_approx\n",
    "    upper_approx_count = len(upper_approx1)\n",
    "    if(lower_approx_count == 0):\n",
    "        roughness = 1\n",
    "    else:   \n",
    "         roughness = 1 - (lower_approx_count/upper_approx_count) # return roughness for a(i) = alpha\n",
    "    return roughness\n",
    "\n",
    "def roughness_numerical_to_categorical(neighborhood , col2_name2 , Data):\n",
    "    \n",
    "    target_set = neighborhood #target set will be neighbourhood of col1\n",
    "    equiv_class_dict = {} #dictionary storing equiv classes for all attribute\n",
    "    for col in Data:\n",
    "        equiv_class_dict[col] =list(Data.groupby([col]))\n",
    "        \n",
    "    arr = equiv_class_dict[col2_name2] #group equiv classes according to column2\n",
    "    lower_approx = []\n",
    "    upper_approx = []\n",
    "    for name,group in arr:\n",
    "       selected_list = list(group.index)\n",
    "       if(set(selected_list).issubset(target_set)): #if a subset, then append to lower_approx\n",
    "            lower_approx.append(selected_list)\n",
    "       if(set(selected_list) & set(target_set)): #if intersection is not null, then append to upper_approx\n",
    "            upper_approx.append(selected_list)\n",
    "    lower_approx_count = sum(map(len, lower_approx)) #count the no. of elements in lower_approx\n",
    "    upper_approx_count = sum(map(len, upper_approx))\n",
    "    if(lower_approx_count == 0):\n",
    "        roughness = 1\n",
    "    else:   \n",
    "         roughness = 1 - (lower_approx_count/upper_approx_count) # return roughness for a(i) = alpha\n",
    "    #print(\"roughness of numerical\", roughness)\n",
    "    return roughness\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def cluster_distance(cluster, Data):\n",
    "        distance = 0\n",
    "        print(\"Cluster\", cluster)\n",
    "        Categorical_Data = Data.ix[cluster]\n",
    "        Numerical_Data = Categorical_Data[['V0']]\n",
    "        Categorical_Data = Categorical_Data.drop(Categorical_Data.columns[[4]], axis = 1)\n",
    "        \n",
    "        \n",
    "        for i in range(0,len(cluster)-1): #categorical\n",
    "              a = np.array(Categorical_Data.ix[cluster[i]])\n",
    "              for k in range(i+1,len(cluster)):\n",
    "                   b = np.array(Categorical_Data.ix[cluster[k]])\n",
    "                   distance += sum(a != b)\n",
    "                \n",
    "        neighborhood_class_dict = {} #calculating neighborhood of numerical attr\n",
    "        threshold = 10\n",
    "        for index, row in Data.iterrows():\n",
    "                        neighbor_list = []\n",
    "                        for index1, row1 in Data.iterrows():\n",
    "                            if((row['V1'] > row1['V1'])):\n",
    "                                if(row['V1'] - row1['V1'] <= threshold):\n",
    "                                    neighbor_list.append(index1)\n",
    "                            elif(row['V1'] < row1['V1']):\n",
    "                                if(row1['V1'] - row['V1'] <= threshold):\n",
    "                                    neighbor_list.append(index1)\n",
    "                            else:        \n",
    "                                neighbor_list.append(index1)\n",
    "                        neighborhood_class_dict[index] = neighbor_list\n",
    "                        \n",
    "        for i in range(0,len(cluster)-1): #for numerical\n",
    "              a = neighborhood_class_dict[i]\n",
    "              for k in range(i+1,len(cluster)):\n",
    "                b = neighborhood_class_dict[k]\n",
    "                if(a!= b):\n",
    "                    distance += 1\n",
    "        \n",
    "                \n",
    "        print(len(cluster))  \n",
    "        final_distance = (2 * distance)/(len(cluster) * (len(cluster)-1)) \n",
    "                  \n",
    "        return final_distance\n",
    "\n",
    "def cluster_numerical(cluster1 , cluster2):\n",
    "    global cluster1_numerical_global \n",
    "    cluster1_numerical_global = cluster1\n",
    "    global cluster2_numerical_global\n",
    "    cluster2_numerical_global = cluster2\n",
    "    #print(\"cluster1_numerical_global\", cluster1_numerical_global)\n",
    "    #print(\"cluster2_numerical_global\", cluster2_numerical_global)\n",
    "   \n",
    "    \n",
    "\n",
    "    \n",
    "def mmer_roughness(Data):\n",
    "    #check if all columns have more than 1 unique values, if not drop that column/columns\n",
    "    #print(\"Dropped columns:\")\n",
    "    #print(Data)\n",
    "    for col1 in Data:\n",
    "         values_in_col_name1 =  list(Data[col1].unique()) #extracting each unique value in column1\n",
    "         #print(col1, len(values_in_col_name1))\n",
    "         if(len(values_in_col_name1) == 1):\n",
    "            Data = Data.drop(col1, axis = 1)\n",
    "            \n",
    "   \n",
    "    \n",
    "    min_mean_roughness = {} #array to store the minimum of average of roughness of each attr\n",
    "    roughness_list_dict = defaultdict(dict) #needed to use 2D dictionary \n",
    "   \n",
    "    \n",
    "    \n",
    "    for col1 in Data:\n",
    "        \n",
    "        neighborhood_class_dict = {} #calculating neighborhood of numerical attr\n",
    "        threshold = 10\n",
    "        for index, row in Data.iterrows():\n",
    "                        neighbor_list = []\n",
    "                        for index1, row1 in Data.iterrows():\n",
    "                            if((row['V1'] > row1['V1'])):\n",
    "                                if(row['V1'] - row1['V1'] <= threshold):\n",
    "                                    neighbor_list.append(index1)\n",
    "                            elif(row['V1'] < row1['V1']):\n",
    "                                if(row1['V1'] - row['V1'] <= threshold):\n",
    "                                    neighbor_list.append(index1)\n",
    "                            else:        \n",
    "                                neighbor_list.append(index1)\n",
    "                        neighborhood_class_dict[index] = neighbor_list\n",
    "        \n",
    "        if(col1 == 'V1'):\n",
    "            \n",
    "             mean_roughness_numerical = [] \n",
    "             roughness_list_dict_numerical = {}\n",
    "             for key in neighborhood_class_dict:             \n",
    "                 roughness_list_numerical = [] \n",
    "                 for col2 in Data:\n",
    "                    if(col1!= col2):   \n",
    "                       roughness_list_numerical.append(roughness_numerical_to_categorical(neighborhood_class_dict[key], col2, Data))\n",
    "                 mean_roughness_numerical.append(sum(roughness_list_numerical)/float(len(roughness_list_numerical)))\n",
    "                 roughness_list_dict_numerical[key] = sum(roughness_list_numerical)/float(len(roughness_list_numerical))\n",
    "                                  \n",
    "             min_mean_roughness['V1'] = (min(mean_roughness_numerical))   \n",
    "             min_roughness_obj =   min(roughness_list_dict_numerical, key= roughness_list_dict_numerical.get)\n",
    "             l = Data.index.tolist()   \n",
    "             cluster1 =  neighborhood_class_dict[min_roughness_obj]\n",
    "             cluster2 =  list(set(l) - set(neighborhood_class_dict[min_roughness_obj]))\n",
    "               \n",
    "                \n",
    "                \n",
    "        values_in_col_name1 =  list(Data[col1].unique()) #extracting each unique value in column1\n",
    "        mean_roughness = [] #list for mean roughness for a(i) = alpha\n",
    "        for val in values_in_col_name1:\n",
    "            roughness_list = [] #array of a(i) = alpha w.r.t. other columns \n",
    "            for col2 in Data:\n",
    "                if(col1!= col2): #not to be compared with itself\n",
    "                  if(col2 == 'V1'):\n",
    "                      roughness_list.append(roughness_categorical_to_numerical(neighborhood_class_dict, col1 , col2, val, Data))\n",
    "                                     \n",
    "                  else:  \n",
    "                      roughness_list.append(roughness(col1 , col2, val, Data))\n",
    "            mean_roughness.append(sum(roughness_list)/float(len(roughness_list)))\n",
    "            roughness_list_dict[col1][val] = sum(roughness_list)/float(len(roughness_list))\n",
    "        min_mean_roughness[col1]=(min(mean_roughness))\n",
    "    for key in min_mean_roughness:\n",
    "        print(key, min_mean_roughness[key]) \n",
    "        \n",
    "    min_roughness_attr = min(min_mean_roughness, key=min_mean_roughness.get) #find the attr with minimum roughness\n",
    "    print(min_roughness_attr)\n",
    "    if(min_roughness_attr == 'V1'):\n",
    "        cluster_numerical(cluster1, cluster2)\n",
    "        return 'V1', 1\n",
    "    \n",
    "    return min_roughness_attr, min(roughness_list_dict[min_roughness_attr])\n",
    "     \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "MMeR(Data,k) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
